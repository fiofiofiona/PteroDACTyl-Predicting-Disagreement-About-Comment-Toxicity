# PteroDACTyl: Predicting Disagreement about Comment Toxicity
### Abstract
Flagging toxic content in online media is not a one-size-fits-all task. While a growing line of research seeks to develop models to detect, classify, and address toxic content, internet users with different backgrounds, experiences, and perspectives often perceive the same piece of content differently â€” one population viewing a certain comment as toxic while another deeming it acceptable. To address this limitation, we built two models (one using DistilBERT as its base, and one using RoBERTa) that predict not only which social media comments appear toxic to different demographics, but also how much disagreement will arise about whether a comment is toxic. We found that the three models performed comparably in terms of accuracy on the task of predicting whether a comment is not toxic, subjectively toxic, or blatantly toxic. The model with RoBERTa base performed slightly better than the other two in terms of F-1 scores.
